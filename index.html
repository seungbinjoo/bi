<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Belief dynamics learning">
  <meta name="keywords" content="bdl">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Language-conditioned and Generalisable Bimanual Robotic Manipulation with Reinforcement Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://seungbinjoo.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://seungbinjoo.github.io/bi/">
            Bi-RMA
          </a>
          <a class="navbar-item" href="https://seungbinjoo.github.io/bdl/">
            Belief Dynamics Learning
          </a>
          <a class="navbar-item" href="https://iopscience.iop.org/article/10.1149/1945-7111/ad59c9/meta">
            SafeBatt
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Belief Dynamics Learning for Contact-Rich Robotic Manipulation via Differentiable Particle Filters</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://seungbinjoo.github.io/">Seung-Bin Joo</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://www.robots.ox.ac.uk/~larab/">Jo√£o F. Henriques</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Oxford,</span>
            <span class="author-block"><sup>2</sup>Visual Geometry Group</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://seungbinjoo.github.io/bi/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/seungbinjoo/bi_rma/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="static/images/1.png" alt="Item 1">
        </div>
        <div class="item item-chair-tp">
          <img src="static/images/2.png" alt="Item 2">
        </div>
        <div class="item item-shiba">
          <img src="static/images/3.png" alt="Item 3">
        </div>
        <div class="item item-fullbody">
          <img src="static/images/4.png" alt="Item 4">
        </div>
        <div class="item item-blueshirt">
          <img src="static/images/5.png" alt="Item 5">
        </div>
        <div class="item item-mask">
          <img src="static/images/6.png" alt="Item 6">
        </div>
        <div class="item item-coffee">
          <img src="static/images/7.png" alt="Item 7">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present a learnable method for object state estimation in blind and contact-rich robotic manipulation settings.
          </p>
          <p>
            Our approach represents the belief as a weighted particle set, and utilizes differentiable particle filters (DPFs), i.e., a differentiable version of the classic particle filter.
            By learning particle proposer and observation likelihood estimator models, we show that blind manipulators can localize objects.
            We learn the measurement update models through supervised learning on a dataset consisting of robot histories.
            Our results show that incorporating a "negative proposing" algorithm helps in improving the performance of DPFs and accounting for sparse contact observations.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Motivation. -->
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
          <p>
            We wish to solve the problem of blind grasping for robotic manipulators by formulating it as a Partially Observable Markov Decision Process (POMDP).
            This involves applying planning algorithms on the belief, i.e. the probability distribution over the true states.
          </p>
          <p>
            The belief update in such continuous state spaces with long horizons and sparse observations is challenging. Thus, our objective is to construct a model \( G \) which can learn the belief dynamics (i.e. next belief from current belief, action, observation):
            \( b' = G(b, a, o) \)
          </p>
        </div>
        <div class="is-flex is-justify-content-center">
          <figure class="image">
            <img src="static/images/Picture1.png" alt="Descriptive text" style="max-height: 300px; width: auto;">
          </figure>
        </div>
      </div>
    </div>
    <!--/ Motivation. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            For a \(d\)-dimensional state space, the belief at time \(t\) is represented as a set of \(n\) particles \(S_t\) and its corresponding weights \(w_t\).
            We use differentiable particle filters (DPFs) with an additional negative proposing algorithm for timesteps when there is an absence of contact observations.
          </p>
        </div>
        <div class="is-flex is-justify-content-center">
          <figure class="image">
            <img src="static/images/method.png" alt="Descriptive text" style="max-height: 1000px; width: auto;">
          </figure>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Learning. -->
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3">Learning the DPF</h2>
        <div class="content has-text-justified">
          <p>
            We learn the differentiable particle filter (DPF) by treating it as a supervised learning problem.
            For the particle proposer \(k_\theta\), from a dataset consisting of [state, action, observation] trajectories, we maximise the belief at the ground truth object state.
            Since our belief is represented as a particle set, we approximate the continuous belief by forming a Gaussian Mixture Model, where each particle \(q_t^{[i]}\)  is a Gaussian scaled by its weight \(w_t^{[i]}\):
            \(\theta_{k}^{*} = argmin_{\theta_{k}} -log E_t[b(q_o;\theta_{k})]\)
          </p>
          <p>
            We learn the observation likelihood estimator \(l_{\theta}\) by maximising log-likelihood of observations in the true object state, and minimising it in all other states:
            \(\theta_{l}^{*} = argmin_{\theta_{l}} -log E_t[l_{\theta}(o_t,s_{t}^{*})] -log E_{t_1, t_2}[1 - l_{\theta}(o_{t_1},s_{t_2}^{*})]\)
          </p>
        </div>
        <div class="is-flex is-justify-content-center">
          <figure class="image">
            <img src="static/images/gmm3.png" alt="Descriptive text" style="max-height: 300px; width: auto;">
          </figure>
        </div>
      </div>
    </div>
    <!--/ Learning. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p>
            We test the DPF for blind grasping, by performing the belief update loop on robot trajectories, and measuring the mean squared error (MSE) between the ground truth object pose and the mean particle of the final-timestep belief.
            Results show that DPF with negative proposing (NP) pipeline paired with optimally generated trajectories outperforms standard DPFs. Click images below to enlarge.
          </p>
        </div>
      </div>
    </div>
    <!--/ Results. -->

    <section class="hero is-light is-small">
      <div class="hero-body">
        <div class="container">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-steve">
              <a href="static/images/r2.png" data-lightbox="carousel" data-title="Item 1">
                <img src="static/images/r2.png" alt="Item 1">
              </a>
            </div>
            <div class="item item-chair-tp">
              <a href="static/images/r4.png" data-lightbox="carousel" data-title="Item 2">
                <img src="static/images/r4.png" alt="Item 2">
              </a>
            </div>
            <div class="item item-shiba">
              <a href="static/images/r6.png" data-lightbox="carousel" data-title="Item 3">
                <img src="static/images/r6.png" alt="Item 3">
              </a>
            </div>
            <div class="item item-fullbody">
              <a href="static/images/r8.png" data-lightbox="carousel" data-title="Item 4">
                <img src="static/images/r8.png" alt="Item 4">
              </a>
            </div>
          </div>
        </div>
      </div>
    </section>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="static/pdfs/EPSRC_POSTER.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/seungbinjoo" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a
              href="https://nerfies.github.io/">here</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
